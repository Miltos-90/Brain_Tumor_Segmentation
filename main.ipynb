{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem definiton\n",
    "\n",
    "Semantic segmentation of gliomas in pre-operative MRI scans. \n",
    "Each MRI consists of 155 240 x 240 patches, in which each pixel is part of a tumor area:\n",
    "\n",
    "The sub-regions of tumor considered for evaluation are: \n",
    "0. The background,\n",
    "1. the necrotic and non-enhancing tumor core (NCR/NET)\n",
    "2. the peritumoral edema (ED), \n",
    "3. the GD-enhancing tumor (ET),\n",
    "\n",
    "According to the [dataset description](https://www.med.upenn.edu/cbica/brats2020/data.html) the multimodel scans are available as NIfTI files (.nii.gz) and describe \n",
    "* a) native (T1)\n",
    "* b) post-contrast T1-weighted (T1Gd)\n",
    "* c) T2-weighted (T2), \n",
    "* d) T2 Fluid Attenuated Inversion Recovery (T2-FLAIR) volumes.\n",
    "\n",
    "These were acquired with different clinical protocols and various scanners from multiple (19) institutions.\n",
    "The provided data are distributed after their pre-processing, i.e., co-registered to the same anatomical template, interpolated to the same resolution (1 mm^3) and skull-stripped.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and data read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T14:42:20.354817Z",
     "iopub.status.busy": "2022-05-29T14:42:20.354461Z",
     "iopub.status.idle": "2022-05-29T14:42:20.362228Z",
     "shell.execute_reply": "2022-05-29T14:42:20.361290Z",
     "shell.execute_reply.started": "2022-05-29T14:42:20.354783Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper scripts\n",
    "import config\n",
    "import utils\n",
    "import engine\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "from torch_lr_finder import LRFinder\n",
    "import nibabel as nib\n",
    "\n",
    "# Make logfile to flush prints\n",
    "import sys\n",
    "old_stdout = sys.stdout # keep reference to existing stdout\n",
    "sys.stdout = open(config.LOG_FILE, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T14:42:22.939514Z",
     "iopub.status.busy": "2022-05-29T14:42:22.938421Z",
     "iopub.status.idle": "2022-05-29T14:44:28.824438Z",
     "shell.execute_reply": "2022-05-29T14:44:28.823820Z",
     "shell.execute_reply.started": "2022-05-29T14:42:22.939455Z"
    }
   },
   "outputs": [],
   "source": [
    "df = utils.collectMetadata()\n",
    "utils.makeSummary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T09:01:13.991495Z",
     "iopub.status.busy": "2022-05-24T09:01:13.990684Z",
     "iopub.status.idle": "2022-05-24T09:01:14.002113Z",
     "shell.execute_reply": "2022-05-24T09:01:14.001131Z",
     "shell.execute_reply.started": "2022-05-24T09:01:13.99146Z"
    }
   },
   "source": [
    "We have a lot of empty patches (these are usually the first few and last few patches on an MRI that are completely empty), and a lot of patches containing only background (i.e. a brain slice with the background label only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T14:44:28.827084Z",
     "iopub.status.busy": "2022-05-29T14:44:28.826528Z",
     "iopub.status.idle": "2022-05-29T14:44:30.569497Z",
     "shell.execute_reply": "2022-05-29T14:44:30.568814Z",
     "shell.execute_reply.started": "2022-05-29T14:44:28.827014Z"
    }
   },
   "outputs": [],
   "source": [
    "for figNo in range(4):\n",
    "    \n",
    "    samplePaths = df[['flairPath', 't1Path', 't1cePath', 't2Path', 'labelPath']].sample(n = 1, random_state = figNo + 44).values[0]\n",
    "\n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = 5, figsize = (15, 5))\n",
    "    for idx, pth in enumerate(samplePaths):\n",
    "\n",
    "        x = np.asarray(nib.load(pth).dataobj)\n",
    "        H, W, D = x.shape\n",
    "        ax[idx].imshow(x[:, :, D // 2], cmap = 'bone')\n",
    "        title = pth.split('/')[-1].split('_')[-1].split('.')[0]\n",
    "        ax[idx].set_title(title)\n",
    "        ax[idx].axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./imm/__results___5_0.png)\n",
    "![alt text](./imm/__results___5_1.png)\n",
    "![alt text](./imm/__results___5_2.png)\n",
    "![alt text](./imm/__results___5_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flair and t2 files seem to provide information regarding the different labels. t1, t1ce will not be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split and subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T14:44:30.571042Z",
     "iopub.status.busy": "2022-05-29T14:44:30.570813Z",
     "iopub.status.idle": "2022-05-29T14:44:30.671763Z",
     "shell.execute_reply": "2022-05-29T14:44:30.671098Z",
     "shell.execute_reply.started": "2022-05-29T14:44:30.571013Z"
    }
   },
   "outputs": [],
   "source": [
    "lvIdx, tIdx = utils.GroupTrainTestSplit(df['subjectID'], \n",
    "                                        testRatio = config.TEST_RATIO, \n",
    "                                        seedNo    = 15)\n",
    "\n",
    "lIdx, vIdx  = utils.GroupTrainTestSplit(df['subjectID'].loc[lvIdx], \n",
    "                                        testRatio = config.VAL_RATIO, \n",
    "                                        seedNo    = 17)\n",
    "\n",
    "traindf, valdf, testdf = df.loc[lIdx], df.loc[vIdx], df.loc[tIdx]\n",
    "\n",
    "traindf = utils.subsample(traindf, config.BACKGROUND_RATIO)\n",
    "valdf   = utils.subsample(valdf,   config.BACKGROUND_RATIO)\n",
    "\n",
    "utils.makeSummary(traindf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T11:05:16.866523Z",
     "iopub.status.busy": "2022-05-24T11:05:16.866028Z",
     "iopub.status.idle": "2022-05-24T11:05:16.872528Z",
     "shell.execute_reply": "2022-05-24T11:05:16.871916Z",
     "shell.execute_reply.started": "2022-05-24T11:05:16.866487Z"
    }
   },
   "source": [
    "That's a bit less than half the original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T14:44:30.674074Z",
     "iopub.status.busy": "2022-05-29T14:44:30.673835Z",
     "iopub.status.idle": "2022-05-29T14:47:02.429279Z",
     "shell.execute_reply": "2022-05-29T14:47:02.428567Z",
     "shell.execute_reply.started": "2022-05-29T14:44:30.674045Z"
    }
   },
   "outputs": [],
   "source": [
    "noTrainSamples, noValSamples = traindf.shape[0], valdf.shape[0]\n",
    "\n",
    "trainTr, valTr = engine.makeTransforms(flairPaths = traindf['flairPath'].unique(),\n",
    "                                       t2Paths    = traindf['t2Path'].unique(),\n",
    "                                       transformationType = config.TRANSFORM_TYPE)\n",
    "\n",
    "trainLoader = utils.makeDataloader(traindf, trainTr, shuffle = True)\n",
    "valLoader   = utils.makeDataloader(valdf,   valTr,   shuffle = False)\n",
    "\n",
    "model       = smp.Unet(encoder_name    = config.ENCODER_NAME,\n",
    "                       encoder_weights = config.ENCODER_WEIGHTS,\n",
    "                       in_channels     = config.ENCODER_IN_CHANNEL,\n",
    "                       classes         = config.NO_CLASSES)\n",
    "\n",
    "criterion   = smp.losses.FocalLoss(mode       = 'multiclass',\n",
    "                                   alpha      = config.LOSS_ALPHA,\n",
    "                                   gamma      = config.LOSS_GAMMA,\n",
    "                                   normalized = config.LOSS_NORM)\n",
    "\n",
    "optimizer   = torch.optim.Adam(model.parameters(), lr = config.LEARN_RATE)\n",
    "scaler      = torch.cuda.amp.GradScaler()\n",
    "scheduler   = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', verbose = True,\n",
    "                                                         factor   = config.SCHEDULER_FACTOR,\n",
    "                                                         patience = config.SCHEDULER_PATIENCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T13:30:15.566295Z",
     "iopub.status.busy": "2022-05-28T13:30:15.566082Z"
    }
   },
   "outputs": [],
   "source": [
    "model.to(config.DEVICE)\n",
    "\n",
    "# Load from a checkpoint if exists\n",
    "model, optimizer, scheduler, scaler, curEpoch, trainLoss, valLoss, bestValLoss = \\\n",
    "    utils.loadCheckpoint(model, optimizer, scheduler, scaler, config.LAST_CHECKPOINT)\n",
    "\n",
    "for epoch in range(curEpoch, config.EPOCHS):\n",
    "    \n",
    "    # train \n",
    "    trainLoss   = engine.train(model, criterion, optimizer, scaler, trainLoader) / noTrainSamples\n",
    "    \n",
    "    # validate\n",
    "    valLoss     = engine.validate(model, criterion, valLoader) / noValSamples\n",
    "    \n",
    "    # reduce LR\n",
    "    if scheduler is not None: scheduler.step(valLoss)\n",
    "        \n",
    "    # Make checkpoint\n",
    "    bestValLoss = utils.makeCheckpoint(epoch, model, optimizer, scheduler, scaler, trainLoss, valLoss, bestValLoss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T14:47:03.705660Z",
     "iopub.status.busy": "2022-05-29T14:47:03.704862Z",
     "iopub.status.idle": "2022-05-29T14:47:04.301158Z",
     "shell.execute_reply": "2022-05-29T14:47:04.300523Z",
     "shell.execute_reply.started": "2022-05-29T14:47:03.705627Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make sure subjects and patches appear in sorted orded\n",
    "testdf = testdf.sort_values(['subjectID', 'patch']).reset_index()\n",
    "\n",
    "# Make dataloader\n",
    "testLoader   = utils.makeDataloader(testdf, valTr, \n",
    "                                    batchSize = D, # One MRI is one batch\n",
    "                                    shuffle   = False)\n",
    "\n",
    "# Load model from best checkpoint\n",
    "checkpoint = torch.load(config.BEST_CHECKPOINT, map_location=torch.device('cpu'))\n",
    "model      = smp.Unet(encoder_name    = config.ENCODER_NAME,\n",
    "                      encoder_weights = config.ENCODER_WEIGHTS,\n",
    "                      in_channels     = config.ENCODER_IN_CHANNEL,\n",
    "                      classes         = config.NO_CLASSES)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:17:24.547258Z",
     "iopub.status.busy": "2022-05-29T15:17:24.546398Z",
     "iopub.status.idle": "2022-05-29T15:17:24.574886Z",
     "shell.execute_reply": "2022-05-29T15:17:24.573925Z",
     "shell.execute_reply.started": "2022-05-29T15:17:24.547206Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "sys.stdout = old_stdout # print here\n",
    "TP, FP, FN, TN = engine.predict(model, testLoader, batchSize = D, noSamples = testdf.shape[0])\n",
    "\n",
    "for idx, className in enumerate(['Background', 'NCR/NET', 'ED', 'ET']):\n",
    "\n",
    "    print(f'---------------------- {className} Class ----------------------')\n",
    "    utils.computeMetrics(TP[:, idx], FP[:, idx], FN[:, idx], TN[:, idx])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
